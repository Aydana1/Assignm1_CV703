{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "from dataset import CUBDataset, DOGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "data_root = \"./CUB_200_2011\"\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "# write data transform here as per the requirement\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(0.1),\n",
    "        # transforms.RandomRotation(45),\n",
    "        # transforms.RandomCrop(224, padding=4),\n",
    "        # transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.RandomAffine(45, (0.3, 0.3), (2, 2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "train_dataset = CUBDataset(image_root_path=f\"{data_root}\", transform=train_transform, split=\"train\")\n",
    "test_dataset = CUBDataset(image_root_path=f\"{data_root}\", transform=test_transform, split=\"test\")\n",
    "\n",
    "\n",
    "train_split = int(len(train_dataset) * 0.8)\n",
    "val_split = len(train_dataset) - train_split\n",
    "train_ds, val_ds = random_split(train_dataset, [train_split, val_split])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, num_workers=1, drop_last=True, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, num_workers=1, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5994 5794\n",
      "74 91\n"
     ]
    }
   ],
   "source": [
    "print( len(train_dataset), len(test_dataset) )\n",
    "print( len(train_loader), len(test_loader) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "tensor([177,  12, 189, 184,  94,  39,  53,  50,  82, 116, 183, 183,  36,  16,\n",
      "         53,  61, 117, 166,  70, 145,  34,   7, 137,  28,  30, 174,  54, 191,\n",
      "         28, 161, 172,  12,  99,   9, 110, 150,  42, 139,  76,  42, 139, 157,\n",
      "          2,  25, 139, 146, 121, 195, 171,  62, 112, 190,  22, 162, 191, 160,\n",
      "        158, 134,  84,  52,   8, 186, 198,  90])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "#     if model_name == \"resnet101\":\n",
    "    model_ft = models.resnet50(pretrained=True, progress=True)\n",
    "#     print(model_ft)\n",
    "    # FREEZE GRADIENTS OF ALL LAYERS\n",
    "    set_parameter_requires_grad(model_ft, True)\n",
    "    # model_ft.layer3[0].conv1 = nn.Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, dilation=2)\n",
    "    # model_ft.layer3[1].conv1 = nn.Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, dilation=3)\n",
    "\n",
    "    # FEATURES FROM THE FINAL LAYER WITH REQUIRES_GRAD = TRUE\n",
    "    # CHANGE CLASS NUMBER FOR FC AND ADD DROPOUT\n",
    "    model_ft.fc = nn.Sequential(\n",
    "#         nn.Linear(1024, 2048),\n",
    "# #         nn.ReLU(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(2048,200)\n",
    "    )  \n",
    "#     print(model_ft)\n",
    "#     num_ftrs = model_ft.fc.in_features\n",
    "#     model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "#     input_size = 224\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=2048, out_features=200, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "# Number of classes in the dataset\n",
    "num_classes = 200\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 30\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "# Initialize the model for this run\n",
    "model, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 409,800 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.1.weight\n",
      "\t fc.1.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param) # PARAMS OF FINAL LAYER TO UPDATE WITH THE OPTIMIZER\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "# ADAM\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "# Observe that all parameters are being optimized\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [10/74] Train Loss: 5.3589\n",
      "Epoch [1/30], Step [20/74] Train Loss: 5.3861\n",
      "Epoch [1/30], Step [30/74] Train Loss: 5.3851\n",
      "Epoch [1/30], Step [40/74] Train Loss: 5.4038\n",
      "Epoch [1/30], Step [50/74] Train Loss: 5.2859\n",
      "Epoch [1/30], Step [60/74] Train Loss: 5.3651\n",
      "Epoch [1/30], Step [70/74] Train Loss: 5.2957\n",
      "Train loss at epoch 1 is 5.3583\n",
      "Train acc at epoch 1 is 0.7601\n",
      "Val loss at epoch 1 is 0.2920\n",
      "Val acc at epoch 1 is 0.9511\n",
      "Epoch [2/30], Step [10/74] Train Loss: 5.1081\n",
      "Epoch [2/30], Step [20/74] Train Loss: 5.1173\n",
      "Epoch [2/30], Step [30/74] Train Loss: 5.1067\n",
      "Epoch [2/30], Step [40/74] Train Loss: 5.0703\n",
      "Epoch [2/30], Step [50/74] Train Loss: 5.0688\n",
      "Epoch [2/30], Step [60/74] Train Loss: 5.0539\n",
      "Epoch [2/30], Step [70/74] Train Loss: 5.0936\n",
      "Train loss at epoch 2 is 5.0959\n",
      "Train acc at epoch 2 is 4.2019\n",
      "Val loss at epoch 2 is 0.2831\n",
      "Val acc at epoch 2 is 4.3308\n",
      "Epoch [3/30], Step [10/74] Train Loss: 4.9548\n",
      "Epoch [3/30], Step [20/74] Train Loss: 4.9337\n",
      "Epoch [3/30], Step [30/74] Train Loss: 4.8939\n",
      "Epoch [3/30], Step [40/74] Train Loss: 4.9156\n",
      "Epoch [3/30], Step [50/74] Train Loss: 4.8756\n",
      "Epoch [3/30], Step [60/74] Train Loss: 4.8835\n",
      "Epoch [3/30], Step [70/74] Train Loss: 4.7955\n",
      "Train loss at epoch 3 is 4.9165\n",
      "Train acc at epoch 3 is 9.2694\n",
      "Val loss at epoch 3 is 0.2712\n",
      "Val acc at epoch 3 is 9.3920\n",
      "Epoch [4/30], Step [10/74] Train Loss: 4.7509\n",
      "Epoch [4/30], Step [20/74] Train Loss: 4.6833\n",
      "Epoch [4/30], Step [30/74] Train Loss: 4.6520\n",
      "Epoch [4/30], Step [40/74] Train Loss: 4.6882\n",
      "Epoch [4/30], Step [50/74] Train Loss: 4.6730\n",
      "Epoch [4/30], Step [60/74] Train Loss: 4.7405\n",
      "Epoch [4/30], Step [70/74] Train Loss: 4.7298\n",
      "Train loss at epoch 4 is 4.7374\n",
      "Train acc at epoch 4 is 14.1258\n",
      "Val loss at epoch 4 is 0.2666\n",
      "Val acc at epoch 4 is 14.1135\n",
      "Epoch [5/30], Step [10/74] Train Loss: 4.5894\n",
      "Epoch [5/30], Step [20/74] Train Loss: 4.5834\n",
      "Epoch [5/30], Step [30/74] Train Loss: 4.6117\n",
      "Epoch [5/30], Step [40/74] Train Loss: 4.5283\n",
      "Epoch [5/30], Step [50/74] Train Loss: 4.5764\n",
      "Epoch [5/30], Step [60/74] Train Loss: 4.5446\n",
      "Epoch [5/30], Step [70/74] Train Loss: 4.4774\n",
      "Train loss at epoch 5 is 4.5637\n",
      "Train acc at epoch 5 is 20.5659\n",
      "Val loss at epoch 5 is 0.2595\n",
      "Val acc at epoch 5 is 19.7520\n",
      "Epoch [6/30], Step [10/74] Train Loss: 4.3377\n",
      "Epoch [6/30], Step [20/74] Train Loss: 4.4141\n",
      "Epoch [6/30], Step [30/74] Train Loss: 4.4520\n",
      "Epoch [6/30], Step [40/74] Train Loss: 4.4083\n",
      "Epoch [6/30], Step [50/74] Train Loss: 4.3812\n",
      "Epoch [6/30], Step [60/74] Train Loss: 4.4302\n",
      "Epoch [6/30], Step [70/74] Train Loss: 4.2840\n",
      "Train loss at epoch 6 is 4.3909\n",
      "Train acc at epoch 6 is 25.9502\n",
      "Val loss at epoch 6 is 0.2523\n",
      "Val acc at epoch 6 is 24.5754\n",
      "Epoch [7/30], Step [10/74] Train Loss: 4.2369\n",
      "Epoch [7/30], Step [20/74] Train Loss: 4.2817\n",
      "Epoch [7/30], Step [30/74] Train Loss: 4.3455\n",
      "Epoch [7/30], Step [40/74] Train Loss: 4.2073\n",
      "Epoch [7/30], Step [50/74] Train Loss: 4.2808\n",
      "Epoch [7/30], Step [60/74] Train Loss: 4.3254\n",
      "Epoch [7/30], Step [70/74] Train Loss: 4.1468\n",
      "Train loss at epoch 7 is 4.2372\n",
      "Train acc at epoch 7 is 30.0887\n",
      "Val loss at epoch 7 is 0.2402\n",
      "Val acc at epoch 7 is 28.7364\n",
      "Epoch [8/30], Step [10/74] Train Loss: 4.0551\n",
      "Epoch [8/30], Step [20/74] Train Loss: 4.1234\n",
      "Epoch [8/30], Step [30/74] Train Loss: 4.0869\n",
      "Epoch [8/30], Step [40/74] Train Loss: 4.1995\n",
      "Epoch [8/30], Step [50/74] Train Loss: 4.0635\n",
      "Epoch [8/30], Step [60/74] Train Loss: 4.0002\n",
      "Epoch [8/30], Step [70/74] Train Loss: 3.9538\n",
      "Train loss at epoch 8 is 4.0907\n",
      "Train acc at epoch 8 is 34.5650\n",
      "Val loss at epoch 8 is 0.2375\n",
      "Val acc at epoch 8 is 32.6427\n",
      "Epoch [9/30], Step [10/74] Train Loss: 3.8897\n",
      "Epoch [9/30], Step [20/74] Train Loss: 3.8472\n",
      "Epoch [9/30], Step [30/74] Train Loss: 4.0458\n",
      "Epoch [9/30], Step [40/74] Train Loss: 3.9378\n",
      "Epoch [9/30], Step [50/74] Train Loss: 4.0188\n",
      "Epoch [9/30], Step [60/74] Train Loss: 3.9823\n",
      "Epoch [9/30], Step [70/74] Train Loss: 3.8760\n",
      "Train loss at epoch 9 is 3.9434\n",
      "Train acc at epoch 9 is 36.8666\n",
      "Val loss at epoch 9 is 0.2288\n",
      "Val acc at epoch 9 is 35.0883\n",
      "Epoch [10/30], Step [10/74] Train Loss: 3.8315\n",
      "Epoch [10/30], Step [20/74] Train Loss: 3.7569\n",
      "Epoch [10/30], Step [30/74] Train Loss: 3.7895\n",
      "Epoch [10/30], Step [40/74] Train Loss: 3.7039\n",
      "Epoch [10/30], Step [50/74] Train Loss: 3.8853\n",
      "Epoch [10/30], Step [60/74] Train Loss: 3.7843\n",
      "Epoch [10/30], Step [70/74] Train Loss: 3.7040\n",
      "Train loss at epoch 10 is 3.8028\n",
      "Train acc at epoch 10 is 39.8438\n",
      "Val loss at epoch 10 is 0.2250\n",
      "Val acc at epoch 10 is 37.5170\n",
      "Epoch [11/30], Step [10/74] Train Loss: 3.6685\n",
      "Epoch [11/30], Step [20/74] Train Loss: 3.7407\n",
      "Epoch [11/30], Step [30/74] Train Loss: 3.7596\n",
      "Epoch [11/30], Step [40/74] Train Loss: 3.6709\n",
      "Epoch [11/30], Step [50/74] Train Loss: 3.7683\n",
      "Epoch [11/30], Step [60/74] Train Loss: 3.6629\n",
      "Epoch [11/30], Step [70/74] Train Loss: 3.7095\n",
      "Train loss at epoch 11 is 3.6983\n",
      "Train acc at epoch 11 is 45.4392\n",
      "Val loss at epoch 11 is 0.2144\n",
      "Val acc at epoch 11 is 42.1705\n",
      "Epoch [12/30], Step [10/74] Train Loss: 3.7119\n",
      "Epoch [12/30], Step [20/74] Train Loss: 3.5792\n",
      "Epoch [12/30], Step [30/74] Train Loss: 3.8429\n",
      "Epoch [12/30], Step [40/74] Train Loss: 3.7292\n",
      "Epoch [12/30], Step [50/74] Train Loss: 3.5865\n",
      "Epoch [12/30], Step [60/74] Train Loss: 3.7039\n",
      "Epoch [12/30], Step [70/74] Train Loss: 3.6092\n",
      "Train loss at epoch 12 is 3.6647\n",
      "Train acc at epoch 12 is 46.1360\n",
      "Val loss at epoch 12 is 0.2190\n",
      "Val acc at epoch 12 is 42.8668\n",
      "Epoch [13/30], Step [10/74] Train Loss: 3.6855\n",
      "Epoch [13/30], Step [20/74] Train Loss: 3.4700\n",
      "Epoch [13/30], Step [30/74] Train Loss: 3.6021\n",
      "Epoch [13/30], Step [40/74] Train Loss: 3.5761\n",
      "Epoch [13/30], Step [50/74] Train Loss: 3.6804\n",
      "Epoch [13/30], Step [60/74] Train Loss: 3.6387\n",
      "Epoch [13/30], Step [70/74] Train Loss: 3.5993\n",
      "Train loss at epoch 13 is 3.6183\n",
      "Train acc at epoch 13 is 46.4527\n",
      "Val loss at epoch 13 is 0.2171\n",
      "Val acc at epoch 13 is 43.3933\n",
      "Epoch [14/30], Step [10/74] Train Loss: 3.5589\n",
      "Epoch [14/30], Step [20/74] Train Loss: 3.5984\n",
      "Epoch [14/30], Step [30/74] Train Loss: 3.4787\n",
      "Epoch [14/30], Step [40/74] Train Loss: 3.7370\n",
      "Epoch [14/30], Step [50/74] Train Loss: 3.5278\n",
      "Epoch [14/30], Step [60/74] Train Loss: 3.5728\n",
      "Epoch [14/30], Step [70/74] Train Loss: 3.5998\n",
      "Train loss at epoch 14 is 3.5693\n",
      "Train acc at epoch 14 is 48.2264\n",
      "Val loss at epoch 14 is 0.2140\n",
      "Val acc at epoch 14 is 44.7860\n",
      "Epoch [15/30], Step [10/74] Train Loss: 3.6270\n",
      "Epoch [15/30], Step [20/74] Train Loss: 3.6083\n",
      "Epoch [15/30], Step [30/74] Train Loss: 3.6118\n",
      "Epoch [15/30], Step [40/74] Train Loss: 3.5387\n",
      "Epoch [15/30], Step [50/74] Train Loss: 3.4401\n",
      "Epoch [15/30], Step [60/74] Train Loss: 3.6812\n",
      "Epoch [15/30], Step [70/74] Train Loss: 3.5017\n",
      "Train loss at epoch 15 is 3.5421\n",
      "Train acc at epoch 15 is 48.6486\n",
      "Val loss at epoch 15 is 0.2137\n",
      "Val acc at epoch 15 is 45.5842\n",
      "Epoch [16/30], Step [10/74] Train Loss: 3.4645\n",
      "Epoch [16/30], Step [20/74] Train Loss: 3.5024\n",
      "Epoch [16/30], Step [30/74] Train Loss: 3.6458\n",
      "Epoch [16/30], Step [40/74] Train Loss: 3.4628\n",
      "Epoch [16/30], Step [50/74] Train Loss: 3.4208\n",
      "Epoch [16/30], Step [60/74] Train Loss: 3.6506\n",
      "Epoch [16/30], Step [70/74] Train Loss: 3.4707\n",
      "Train loss at epoch 16 is 3.4945\n",
      "Train acc at epoch 16 is 50.1689\n",
      "Val loss at epoch 16 is 0.2113\n",
      "Val acc at epoch 16 is 46.2806\n",
      "Epoch [17/30], Step [10/74] Train Loss: 3.5206\n",
      "Epoch [17/30], Step [20/74] Train Loss: 3.3500\n",
      "Epoch [17/30], Step [30/74] Train Loss: 3.3254\n",
      "Epoch [17/30], Step [40/74] Train Loss: 3.4497\n",
      "Epoch [17/30], Step [50/74] Train Loss: 3.3840\n",
      "Epoch [17/30], Step [60/74] Train Loss: 3.3155\n",
      "Epoch [17/30], Step [70/74] Train Loss: 3.3821\n",
      "Train loss at epoch 17 is 3.4560\n",
      "Train acc at epoch 17 is 49.5355\n",
      "Val loss at epoch 17 is 0.2058\n",
      "Val acc at epoch 17 is 46.0428\n",
      "Epoch [18/30], Step [10/74] Train Loss: 3.3393\n",
      "Epoch [18/30], Step [20/74] Train Loss: 3.3697\n",
      "Epoch [18/30], Step [30/74] Train Loss: 3.4830\n",
      "Epoch [18/30], Step [40/74] Train Loss: 3.5196\n",
      "Epoch [18/30], Step [50/74] Train Loss: 3.4370\n",
      "Epoch [18/30], Step [60/74] Train Loss: 3.3629\n",
      "Epoch [18/30], Step [70/74] Train Loss: 3.4539\n",
      "Train loss at epoch 18 is 3.4249\n",
      "Train acc at epoch 18 is 49.4932\n",
      "Val loss at epoch 18 is 0.2014\n",
      "Val acc at epoch 18 is 46.0258\n",
      "Epoch [19/30], Step [10/74] Train Loss: 3.5339\n",
      "Epoch [19/30], Step [20/74] Train Loss: 3.3728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Step [30/74] Train Loss: 3.4985\n",
      "Epoch [19/30], Step [40/74] Train Loss: 3.4080\n",
      "Epoch [19/30], Step [50/74] Train Loss: 3.2782\n",
      "Epoch [19/30], Step [60/74] Train Loss: 3.3439\n",
      "Epoch [19/30], Step [70/74] Train Loss: 3.2578\n",
      "Train loss at epoch 19 is 3.3795\n",
      "Train acc at epoch 19 is 51.2458\n",
      "Val loss at epoch 19 is 0.2100\n",
      "Val acc at epoch 19 is 47.6902\n",
      "Epoch [20/30], Step [10/74] Train Loss: 3.3123\n",
      "Epoch [20/30], Step [20/74] Train Loss: 3.3863\n",
      "Epoch [20/30], Step [30/74] Train Loss: 3.3841\n",
      "Epoch [20/30], Step [40/74] Train Loss: 3.3221\n",
      "Epoch [20/30], Step [50/74] Train Loss: 3.3284\n",
      "Epoch [20/30], Step [60/74] Train Loss: 3.1377\n",
      "Epoch [20/30], Step [70/74] Train Loss: 3.2472\n",
      "Train loss at epoch 20 is 3.3642\n",
      "Train acc at epoch 20 is 50.4856\n",
      "Val loss at epoch 20 is 0.2052\n",
      "Val acc at epoch 20 is 47.1807\n",
      "Epoch [21/30], Step [10/74] Train Loss: 3.3664\n",
      "Epoch [21/30], Step [20/74] Train Loss: 3.2911\n",
      "Epoch [21/30], Step [30/74] Train Loss: 3.2064\n",
      "Epoch [21/30], Step [40/74] Train Loss: 3.3427\n",
      "Epoch [21/30], Step [50/74] Train Loss: 3.1725\n",
      "Epoch [21/30], Step [60/74] Train Loss: 3.2572\n",
      "Epoch [21/30], Step [70/74] Train Loss: 3.4324\n",
      "Train loss at epoch 21 is 3.3249\n",
      "Train acc at epoch 21 is 51.8370\n",
      "Val loss at epoch 21 is 0.1828\n",
      "Val acc at epoch 21 is 48.0978\n",
      "Epoch [22/30], Step [10/74] Train Loss: 3.2704\n",
      "Epoch [22/30], Step [20/74] Train Loss: 3.4973\n",
      "Epoch [22/30], Step [30/74] Train Loss: 3.5045\n",
      "Epoch [22/30], Step [40/74] Train Loss: 3.3588\n",
      "Epoch [22/30], Step [50/74] Train Loss: 3.1907\n",
      "Epoch [22/30], Step [60/74] Train Loss: 3.3509\n",
      "Epoch [22/30], Step [70/74] Train Loss: 3.3259\n",
      "Train loss at epoch 22 is 3.3146\n",
      "Train acc at epoch 22 is 51.7736\n",
      "Val loss at epoch 22 is 0.1992\n",
      "Val acc at epoch 22 is 47.9959\n",
      "Epoch [23/30], Step [10/74] Train Loss: 3.2527\n",
      "Epoch [23/30], Step [20/74] Train Loss: 3.4719\n",
      "Epoch [23/30], Step [30/74] Train Loss: 3.1611\n",
      "Epoch [23/30], Step [40/74] Train Loss: 3.2790\n",
      "Epoch [23/30], Step [50/74] Train Loss: 3.4053\n",
      "Epoch [23/30], Step [60/74] Train Loss: 3.2411\n",
      "Epoch [23/30], Step [70/74] Train Loss: 3.2168\n",
      "Train loss at epoch 23 is 3.2994\n",
      "Train acc at epoch 23 is 52.8927\n",
      "Val loss at epoch 23 is 0.1984\n",
      "Val acc at epoch 23 is 49.1848\n",
      "Epoch [24/30], Step [10/74] Train Loss: 3.4235\n",
      "Epoch [24/30], Step [20/74] Train Loss: 3.1427\n",
      "Epoch [24/30], Step [30/74] Train Loss: 3.4245\n",
      "Epoch [24/30], Step [40/74] Train Loss: 3.4018\n",
      "Epoch [24/30], Step [50/74] Train Loss: 3.1247\n",
      "Epoch [24/30], Step [60/74] Train Loss: 3.3753\n",
      "Epoch [24/30], Step [70/74] Train Loss: 3.3871\n",
      "Train loss at epoch 24 is 3.2878\n",
      "Train acc at epoch 24 is 52.4282\n",
      "Val loss at epoch 24 is 0.1992\n",
      "Val acc at epoch 24 is 48.6413\n",
      "Epoch [25/30], Step [10/74] Train Loss: 3.0081\n",
      "Epoch [25/30], Step [20/74] Train Loss: 3.0654\n",
      "Epoch [25/30], Step [30/74] Train Loss: 3.3637\n",
      "Epoch [25/30], Step [40/74] Train Loss: 3.2314\n",
      "Epoch [25/30], Step [50/74] Train Loss: 3.1425\n",
      "Epoch [25/30], Step [60/74] Train Loss: 3.3233\n",
      "Epoch [25/30], Step [70/74] Train Loss: 3.2025\n",
      "Train loss at epoch 25 is 3.2811\n",
      "Train acc at epoch 25 is 52.7449\n",
      "Val loss at epoch 25 is 0.2051\n",
      "Val acc at epoch 25 is 49.0829\n",
      "Epoch [26/30], Step [10/74] Train Loss: 3.1805\n",
      "Epoch [26/30], Step [20/74] Train Loss: 3.2419\n",
      "Epoch [26/30], Step [30/74] Train Loss: 3.1913\n",
      "Epoch [26/30], Step [40/74] Train Loss: 3.2182\n",
      "Epoch [26/30], Step [50/74] Train Loss: 3.2876\n",
      "Epoch [26/30], Step [60/74] Train Loss: 3.3966\n",
      "Epoch [26/30], Step [70/74] Train Loss: 3.2793\n",
      "Train loss at epoch 26 is 3.2756\n",
      "Train acc at epoch 26 is 52.6605\n",
      "Val loss at epoch 26 is 0.2005\n",
      "Val acc at epoch 26 is 49.0489\n",
      "Epoch [27/30], Step [10/74] Train Loss: 3.2270\n",
      "Epoch [27/30], Step [20/74] Train Loss: 3.2490\n",
      "Epoch [27/30], Step [30/74] Train Loss: 3.2972\n",
      "Epoch [27/30], Step [40/74] Train Loss: 3.3387\n",
      "Epoch [27/30], Step [50/74] Train Loss: 3.2443\n",
      "Epoch [27/30], Step [60/74] Train Loss: 3.2730\n",
      "Epoch [27/30], Step [70/74] Train Loss: 3.0872\n",
      "Train loss at epoch 27 is 3.2552\n",
      "Train acc at epoch 27 is 53.0828\n",
      "Val loss at epoch 27 is 0.1924\n",
      "Val acc at epoch 27 is 49.3207\n",
      "Epoch [28/30], Step [10/74] Train Loss: 3.2360\n",
      "Epoch [28/30], Step [20/74] Train Loss: 3.1777\n",
      "Epoch [28/30], Step [30/74] Train Loss: 3.1770\n",
      "Epoch [28/30], Step [40/74] Train Loss: 3.2975\n",
      "Epoch [28/30], Step [50/74] Train Loss: 3.3681\n",
      "Epoch [28/30], Step [60/74] Train Loss: 3.2683\n",
      "Epoch [28/30], Step [70/74] Train Loss: 3.1537\n",
      "Train loss at epoch 28 is 3.2449\n",
      "Train acc at epoch 28 is 52.4704\n",
      "Val loss at epoch 28 is 0.1943\n",
      "Val acc at epoch 28 is 48.7602\n",
      "Epoch [29/30], Step [10/74] Train Loss: 3.1544\n",
      "Epoch [29/30], Step [20/74] Train Loss: 3.3841\n",
      "Epoch [29/30], Step [30/74] Train Loss: 3.0295\n",
      "Epoch [29/30], Step [40/74] Train Loss: 3.3711\n",
      "Epoch [29/30], Step [50/74] Train Loss: 3.2705\n",
      "Epoch [29/30], Step [60/74] Train Loss: 3.0411\n",
      "Epoch [29/30], Step [70/74] Train Loss: 3.2458\n",
      "Train loss at epoch 29 is 3.2371\n",
      "Train acc at epoch 29 is 53.4206\n",
      "Val loss at epoch 29 is 0.2048\n",
      "Val acc at epoch 29 is 49.5075\n",
      "Epoch [30/30], Step [10/74] Train Loss: 3.2471\n",
      "Epoch [30/30], Step [20/74] Train Loss: 3.2575\n",
      "Epoch [30/30], Step [30/74] Train Loss: 2.9954\n",
      "Epoch [30/30], Step [40/74] Train Loss: 3.2669\n",
      "Epoch [30/30], Step [50/74] Train Loss: 3.0619\n",
      "Epoch [30/30], Step [60/74] Train Loss: 3.2773\n",
      "Epoch [30/30], Step [70/74] Train Loss: 3.0592\n",
      "Train loss at epoch 30 is 3.2058\n",
      "Train acc at epoch 30 is 54.7508\n",
      "Val loss at epoch 30 is 0.1929\n",
      "Val acc at epoch 30 is 50.5774\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "curr_lr = learning_rate\n",
    "# val_losses = np.array([])\n",
    "# train_losses = np.array([])\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "\n",
    "myfile = open('myfile__resnet50_txt', 'w')\n",
    "myfile.write('Training results: \\n')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    correct=0\n",
    "    total=0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        # print(images.shape)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimizes\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Train Loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    acc = 100.*correct/total\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(acc)\n",
    "    print('Train loss at epoch {} is {:.4f}'.format(epoch+1, train_loss))\n",
    "    print('Train acc at epoch {} is {:.4f}'.format(epoch+1, acc))\n",
    "    myfile.write('Train loss at epoch {} is {:.4f}\\n'.format(epoch+1, train_loss))\n",
    "    myfile.write('Train acc at epoch {} is {:.4f}\\n'.format(epoch+1, acc))\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    val_loss = loss / len(val_loader) \n",
    "    acc = 100.*correct/total\n",
    "    val_losses.append(val_loss)\n",
    "    val_acc.append(acc)\n",
    "    print('Val loss at epoch {} is {:.4f}'.format(epoch+1, val_loss))\n",
    "    print('Val acc at epoch {} is {:.4f}'.format(epoch+1, acc))\n",
    "    myfile.write('Val loss at epoch {} is {:.4f}\\n'.format(epoch+1, val_loss))\n",
    "    myfile.write('Val acc at epoch {} is {:.4f}\\n'.format(epoch+1, acc))    \n",
    "\n",
    "    # Decay learning rate\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "\n",
    "\n",
    "myfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_checkpoints/model_resnet50.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train','Valid'])\n",
    "plt.title('Train vs Valid Accuracy')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 33.59375 %\n"
     ]
    }
   ],
   "source": [
    " # Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# # Save the model checkpoint\n",
    "# torch.save(model.state_dict(), model.name + '.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc289c304aa67a903225ac755337f14ca9e86f378cf8d96233e0cc690cb604b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
