{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab74f3b6",
   "metadata": {},
   "source": [
    "# Dataloaders for CUB Birds, Stanford Dogs, Foodx dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832ec63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidana/anaconda3/envs/aaico/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, models, transforms\n\u001b[0;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08c99b",
   "metadata": {},
   "source": [
    "## CUB Birds Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed5ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUBDataset(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    Dataset class for CUB Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_root_path, caption_root_path=None, split=\"train\", *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_root_path:      path to dir containing images and lists folders\n",
    "            caption_root_path:    path to dir containing captions\n",
    "            split:          train / test\n",
    "            *args:\n",
    "            **kwargs:\n",
    "        \"\"\"\n",
    "        image_info = self.get_file_content(f\"{image_root_path}/images.txt\")\n",
    "        self.image_id_to_name = {y[0]: y[1] for y in [x.strip().split(\" \") for x in image_info]}\n",
    "        split_info = self.get_file_content(f\"{image_root_path}/train_test_split.txt\")\n",
    "        self.split_info = {self.image_id_to_name[y[0]]: y[1] for y in [x.strip().split(\" \") for x in split_info]}\n",
    "        self.split = \"1\" if split == \"train\" else \"0\"\n",
    "        self.caption_root_path = caption_root_path\n",
    "\n",
    "        super(CUBDataset, self).__init__(root=f\"{image_root_path}/images\", is_valid_file=self.is_valid_file,\n",
    "                                         *args, **kwargs)\n",
    "\n",
    "    def is_valid_file(self, x):\n",
    "        return self.split_info[(x[len(self.root) + 1:])] == self.split\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_content(file_path):\n",
    "        with open(file_path) as fo:\n",
    "            content = fo.readlines()\n",
    "        return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def8051",
   "metadata": {},
   "source": [
    "### Use the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8dfb049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5994, 5794)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1d3e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 182)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbf6203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([125, 197, 131, 193,  33, 190, 112, 157,  60,   0, 197, 178,  53,  95,\n",
      "        198, 129,   6,  67,  38, 155,  94, 168, 152,  75,  68,  81, 167, 127,\n",
      "          7, 122, 160,   9])\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4695f",
   "metadata": {},
   "source": [
    "## Stanford Dog Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c1c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56baa219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOGDataset(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"\n",
    "    Dataset class for DOG Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_root_path, caption_root_path=None, split=\"train\", *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_root_path:      path to dir containing images and lists folders\n",
    "            caption_root_path:    path to dir containing captions\n",
    "            split:          train / test\n",
    "            *args:\n",
    "            **kwargs:\n",
    "        \"\"\"\n",
    "        image_info = self.get_file_content(f\"{image_root_path}splits/file_list.mat\")\n",
    "        image_files = [o[0][0] for o in image_info]\n",
    "        \n",
    "        split_info = self.get_file_content(f\"{image_root_path}/splits/{split}_list.mat\")\n",
    "        split_files = [o[0][0] for o in split_info]\n",
    "        self.split_info = {}\n",
    "        if split == 'train' :\n",
    "            for image in image_files:\n",
    "                if image in split_files:\n",
    "                    self.split_info[image] = \"1\"\n",
    "                else:\n",
    "                    self.split_info[image] = \"0\"\n",
    "        elif split== 'test' :\n",
    "            for image in image_files:\n",
    "                if image in split_files:\n",
    "                    self.split_info[image] = \"0\"\n",
    "                else:\n",
    "                    self.split_info[image] = \"1\"\n",
    "                    \n",
    "        self.split = \"1\" if split == \"train\" else \"0\"\n",
    "        self.caption_root_path = caption_root_path\n",
    "\n",
    "        super(DOGDataset, self).__init__(root=f\"{image_root_path}Images\", is_valid_file = self.is_valid_file,\n",
    "                                         *args, **kwargs)\n",
    "\n",
    "    def is_valid_file(self, x):\n",
    "        return self.split_info[(x[len(self.root) + 1:])] == self.split\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_content(file_path):\n",
    "        content =  scipy.io.loadmat(file_path)\n",
    "        return content['file_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train and test set\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "\n",
    "data_root = \"./dog/\"\n",
    "\n",
    "train_dataset = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n",
    "print('Number of train samples:', len(train_dataset))\n",
    "print('Number of test samples:', len(test_dataset))\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2032ad9",
   "metadata": {},
   "source": [
    "### Use Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35eeca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6f020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60bcea62",
   "metadata": {},
   "source": [
    "## Food Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c4191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"food_dataset\"\n",
    "\n",
    "split = 'train'\n",
    "train_df = pd.read_csv(f'{data_dir}/annot/{split}_info.csv', names= ['image_name','label'])\n",
    "train_df['path'] = train_df['image_name'].map(lambda x: os.path.join(f'./{split}/{split}_set/', x))\n",
    "\n",
    "\n",
    "split = 'val'\n",
    "val_df = pd.read_csv(f'{data_dir}/annot/{split}_info.csv', names= ['image_name','label'])\n",
    "val_df['path'] = val_df['image_name'].map(lambda x: os.path.join(f'./{split}/{split}_set/', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOODDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        return (\n",
    "            torchvision.transforms.functional.to_tensor(Image.open(row[\"path\"])), row['label']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f783c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FOODDataset(train_df)\n",
    "val_dataset = FOODDataset(val_df)\n",
    "\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, drop_last=True, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75948c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b88815",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    print('='*50)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a61bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930acb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12a2fa43",
   "metadata": {},
   "source": [
    "## Concatenate CUB Birds and Stanford Dogs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./CUB_200_2011\"\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "# write data transform here as per the requirement\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "train_dataset_cub = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset_cub = CUBDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train and test set\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "\n",
    "data_root = \"./dog/\"\n",
    "\n",
    "train_dataset_dog = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"train\")\n",
    "test_dataset_dog = DOGDataset(image_root_path=f\"{data_root}\", transform=data_transform, split=\"test\")\n",
    "print('Number of train samples:', len(train_dataset_dog))\n",
    "print('Number of test samples:', len(test_dataset_dog))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ba294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated dataloader for CUB and DOG\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([train_dataset_cub, train_dataset_dog]),\n",
    "             batch_size=1, shuffle=True,\n",
    "             num_workers=1, pin_memory=True)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "             torch.utils.data.ConcatDataset([test_dataset_cub, test_dataset_dog]),\n",
    "             batch_size=1, shuffle=True,\n",
    "             num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset_cub), len(train_dataset_dog), len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset_cub), len(test_dataset_dog), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee5eac",
   "metadata": {},
   "source": [
    "### Iterate Concatenated dataloader images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5524a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "\n",
    "    print('image :: ', inputs.shape)\n",
    "    print(targets)\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f41a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc289c304aa67a903225ac755337f14ca9e86f378cf8d96233e0cc690cb604b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
