{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "# from augmentation import *\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.models.resnet import resnet18, resnet34, resnet50, resnet101\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import timm\n",
    "\n",
    "# data_root = \"../datasets/CUB_200_2011/\"\n",
    "# learning_rate = 0.0001\n",
    "# # batch_size = 128\n",
    "\n",
    "\n",
    "from models.models import deit_small_patch16_224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CUBDataset\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "data_root = \"./CUB_200_2011\"\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "# write data transform here as per the requirement\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.RandomVerticalFlip(0.1),\n",
    "        # transforms.RandomRotation(45),\n",
    "        # transforms.RandomCrop(224, padding=4),\n",
    "        # transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        # transforms.RandomAffine(45, (0.3, 0.3), (2, 2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "train_dataset = CUBDataset(image_root_path=f\"{data_root}\", transform=train_transform, split=\"train\")\n",
    "test_dataset = CUBDataset(image_root_path=f\"{data_root}\", transform=test_transform, split=\"test\")\n",
    "\n",
    "\n",
    "train_split = int(len(train_dataset) * 0.9)\n",
    "val_split = len(train_dataset) - train_split\n",
    "train_ds, val_ds = random_split(train_dataset, [train_split, val_split])\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "# load in into the torch dataloader to get variable batch size, shuffle \n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, num_workers=1, drop_last=True, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, num_workers=1, drop_last=True, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=1, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_loader import FOODDataset\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "sz = 448\n",
    "test_transform=transforms.Compose([\n",
    "                    transforms.Resize((sz, sz)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def food_dataset(data_dir = \"/home/sultan.abughazal/Public/foodx-251-dataset\",\n",
    "                 data_transform=transforms.Compose([\n",
    "                     transforms.Resize((224, 224)),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                 ]),\n",
    "                    bs=128\n",
    "                 ):\n",
    "\n",
    "\n",
    "    split = 'train'\n",
    "    train_df = pd.read_csv(f'{data_dir}/{split}_labels.csv', names=['image_name', 'label'])\n",
    "    train_df['path'] = train_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}_set/', x))\n",
    "\n",
    "    # print(train_df)\n",
    "    train_df = train_df.drop(0)\n",
    "    # print(train_df)\n",
    "    split = 'val'\n",
    "    val_df = pd.read_csv(f'{data_dir}/{split}_labels.csv', names=['image_name', 'label'])\n",
    "    val_df['path'] = val_df['image_name'].map(lambda x: os.path.join(f'{data_dir}/{split}_set/', x))\n",
    "    val_df = val_df.drop(0)\n",
    "    \n",
    "    train_dataset = FOODDataset(train_df, transform=data_transform)\n",
    "    test_dataset = FOODDataset(val_df, transform=test_transform)\n",
    "\n",
    "    lengths = [int(len(train_dataset) * 0.9), int(len(train_dataset) * 0.1) + 1]\n",
    "    torch.manual_seed(0)\n",
    "    train_set, val_set = random_split(train_dataset, lengths)\n",
    "    # load in into the torch dataloader to get variable batch size, shuffle\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=bs, drop_last=True, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=bs, drop_last=True, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, drop_last=False, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'food_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a2a9d98310fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfood_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'food_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = food_dataset()\n",
    "\n",
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('*resnetv2*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnetv2_50x1_bitm', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d((1,1)),\n",
    "    nn.Conv2d(2048, 200, kernel_size=(1, 1), stride=(1, 1)),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "#         for param in model.parameters():\n",
    "#             param.requires_grad = False\n",
    "        ct = 0\n",
    "        for child in model.children():\n",
    "            ct += 1\n",
    "            if ct < 4:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "set_parameter_requires_grad(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (stem): Sequential(\n",
       "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ResNetStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): PreActBottleneck(\n",
       "          (downsample): DownsampleConv(\n",
       "            (conv): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResNetStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): PreActBottleneck(\n",
       "          (downsample): DownsampleConv(\n",
       "            (conv): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResNetStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): PreActBottleneck(\n",
       "          (downsample): DownsampleConv(\n",
       "            (conv): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResNetStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): PreActBottleneck(\n",
       "          (downsample): DownsampleConv(\n",
       "            (conv): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 2048, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 2048, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): GroupNormAct(\n",
       "    32, 2048, eps=1e-05, affine=True\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Conv2d(2048, 200, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 409,800 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [10/42] Train Loss: 5.3193\n",
      "Epoch [1/50], Step [20/42] Train Loss: 4.7071\n",
      "Epoch [1/50], Step [30/42] Train Loss: 4.2347\n",
      "Epoch [1/50], Step [40/42] Train Loss: 4.0301\n",
      "Train loss at epoch 1 is 4.8603\n",
      "Train acc at epoch 1 is 7.5335\n",
      "Val loss at epoch 1 is 0.9812\n",
      "Val acc at epoch 1 is 8.6277\n",
      "Epoch [2/50], Step [10/42] Train Loss: 3.2876\n",
      "Epoch [2/50], Step [20/42] Train Loss: 2.8706\n",
      "Epoch [2/50], Step [30/42] Train Loss: 2.6980\n",
      "Epoch [2/50], Step [40/42] Train Loss: 2.4253\n",
      "Train loss at epoch 2 is 3.0030\n",
      "Train acc at epoch 2 is 38.7277\n",
      "Val loss at epoch 2 is 0.6457\n",
      "Val acc at epoch 2 is 38.9266\n",
      "Epoch [3/50], Step [10/42] Train Loss: 2.0700\n",
      "Epoch [3/50], Step [20/42] Train Loss: 2.1635\n",
      "Epoch [3/50], Step [30/42] Train Loss: 1.9794\n",
      "Epoch [3/50], Step [40/42] Train Loss: 1.9046\n",
      "Train loss at epoch 3 is 1.9908\n",
      "Train acc at epoch 3 is 60.9747\n",
      "Val loss at epoch 3 is 0.5158\n",
      "Val acc at epoch 3 is 60.4959\n",
      "Epoch [4/50], Step [10/42] Train Loss: 1.4434\n",
      "Epoch [4/50], Step [20/42] Train Loss: 1.4838\n",
      "Epoch [4/50], Step [30/42] Train Loss: 1.3820\n",
      "Epoch [4/50], Step [40/42] Train Loss: 1.4627\n",
      "Train loss at epoch 4 is 1.4454\n",
      "Train acc at epoch 4 is 72.6562\n",
      "Val loss at epoch 4 is 0.4873\n",
      "Val acc at epoch 4 is 71.5353\n",
      "Epoch [5/50], Step [10/42] Train Loss: 1.2435\n",
      "Epoch [5/50], Step [20/42] Train Loss: 1.1957\n",
      "Epoch [5/50], Step [30/42] Train Loss: 1.0702\n",
      "Epoch [5/50], Step [40/42] Train Loss: 1.1123\n",
      "Train loss at epoch 5 is 1.1390\n",
      "Train acc at epoch 5 is 78.4970\n",
      "Val loss at epoch 5 is 0.3534\n",
      "Val acc at epoch 5 is 77.3098\n",
      "Epoch [6/50], Step [10/42] Train Loss: 0.9396\n",
      "Epoch [6/50], Step [20/42] Train Loss: 0.9420\n",
      "Epoch [6/50], Step [30/42] Train Loss: 1.0098\n",
      "Epoch [6/50], Step [40/42] Train Loss: 0.8346\n",
      "Train loss at epoch 6 is 0.9372\n",
      "Train acc at epoch 6 is 82.0312\n",
      "Val loss at epoch 6 is 0.3202\n",
      "Val acc at epoch 6 is 80.7575\n",
      "Epoch [7/50], Step [10/42] Train Loss: 0.7798\n",
      "Epoch [7/50], Step [20/42] Train Loss: 0.8087\n",
      "Epoch [7/50], Step [30/42] Train Loss: 0.7327\n",
      "Epoch [7/50], Step [40/42] Train Loss: 0.6479\n",
      "Train loss at epoch 7 is 0.7968\n",
      "Train acc at epoch 7 is 85.4725\n",
      "Val loss at epoch 7 is 0.3535\n",
      "Val acc at epoch 7 is 83.9844\n",
      "Epoch [8/50], Step [10/42] Train Loss: 0.6813\n",
      "Epoch [8/50], Step [20/42] Train Loss: 0.7574\n",
      "Epoch [8/50], Step [30/42] Train Loss: 0.5734\n",
      "Epoch [8/50], Step [40/42] Train Loss: 0.7226\n",
      "Train loss at epoch 8 is 0.6878\n",
      "Train acc at epoch 8 is 88.1882\n",
      "Val loss at epoch 8 is 0.3240\n",
      "Val acc at epoch 8 is 86.7018\n",
      "Epoch [9/50], Step [10/42] Train Loss: 0.5509\n",
      "Epoch [9/50], Step [20/42] Train Loss: 0.6565\n",
      "Epoch [9/50], Step [30/42] Train Loss: 0.5991\n",
      "Epoch [9/50], Step [40/42] Train Loss: 0.5086\n",
      "Train loss at epoch 9 is 0.6061\n",
      "Train acc at epoch 9 is 89.8810\n",
      "Val loss at epoch 9 is 0.3084\n",
      "Val acc at epoch 9 is 88.2133\n",
      "Epoch [10/50], Step [10/42] Train Loss: 0.5160\n",
      "Epoch [10/50], Step [20/42] Train Loss: 0.5559\n",
      "Epoch [10/50], Step [30/42] Train Loss: 0.5260\n",
      "Epoch [10/50], Step [40/42] Train Loss: 0.4759\n",
      "Train loss at epoch 10 is 0.5404\n",
      "Train acc at epoch 10 is 91.3504\n",
      "Val loss at epoch 10 is 0.2965\n",
      "Val acc at epoch 10 is 89.7758\n",
      "Epoch [11/50], Step [10/42] Train Loss: 0.4703\n",
      "Epoch [11/50], Step [20/42] Train Loss: 0.4591\n",
      "Epoch [11/50], Step [30/42] Train Loss: 0.4864\n",
      "Epoch [11/50], Step [40/42] Train Loss: 0.5290\n",
      "Train loss at epoch 11 is 0.4834\n",
      "Train acc at epoch 11 is 93.3594\n",
      "Val loss at epoch 11 is 0.2889\n",
      "Val acc at epoch 11 is 91.6610\n",
      "Epoch [12/50], Step [10/42] Train Loss: 0.3845\n",
      "Epoch [12/50], Step [20/42] Train Loss: 0.5034\n",
      "Epoch [12/50], Step [30/42] Train Loss: 0.4628\n",
      "Epoch [12/50], Step [40/42] Train Loss: 0.4524\n",
      "Train loss at epoch 12 is 0.4638\n",
      "Train acc at epoch 12 is 93.6012\n",
      "Val loss at epoch 12 is 0.2854\n",
      "Val acc at epoch 12 is 91.8988\n",
      "Epoch [13/50], Step [10/42] Train Loss: 0.5463\n",
      "Epoch [13/50], Step [20/42] Train Loss: 0.3696\n",
      "Epoch [13/50], Step [30/42] Train Loss: 0.4497\n",
      "Epoch [13/50], Step [40/42] Train Loss: 0.5089\n",
      "Train loss at epoch 13 is 0.4476\n",
      "Train acc at epoch 13 is 94.0662\n",
      "Val loss at epoch 13 is 0.2426\n",
      "Val acc at epoch 13 is 92.2554\n",
      "Epoch [14/50], Step [10/42] Train Loss: 0.4607\n",
      "Epoch [14/50], Step [20/42] Train Loss: 0.4429\n",
      "Epoch [14/50], Step [30/42] Train Loss: 0.4394\n",
      "Epoch [14/50], Step [40/42] Train Loss: 0.3660\n",
      "Train loss at epoch 14 is 0.4331\n",
      "Train acc at epoch 14 is 94.3080\n",
      "Val loss at epoch 14 is 0.2959\n",
      "Val acc at epoch 14 is 92.5442\n",
      "Epoch [15/50], Step [10/42] Train Loss: 0.3850\n",
      "Epoch [15/50], Step [20/42] Train Loss: 0.3860\n",
      "Epoch [15/50], Step [30/42] Train Loss: 0.4676\n",
      "Epoch [15/50], Step [40/42] Train Loss: 0.3833\n",
      "Train loss at epoch 15 is 0.4188\n",
      "Train acc at epoch 15 is 94.6987\n",
      "Val loss at epoch 15 is 0.3004\n",
      "Val acc at epoch 15 is 92.7989\n",
      "Epoch [16/50], Step [10/42] Train Loss: 0.4409\n",
      "Epoch [16/50], Step [20/42] Train Loss: 0.3750\n",
      "Epoch [16/50], Step [30/42] Train Loss: 0.4045\n",
      "Epoch [16/50], Step [40/42] Train Loss: 0.3453\n",
      "Train loss at epoch 16 is 0.4041\n",
      "Train acc at epoch 16 is 95.0521\n",
      "Val loss at epoch 16 is 0.2154\n",
      "Val acc at epoch 16 is 93.1046\n",
      "Epoch [17/50], Step [10/42] Train Loss: 0.3586\n",
      "Epoch [17/50], Step [20/42] Train Loss: 0.3913\n",
      "Epoch [17/50], Step [30/42] Train Loss: 0.3412\n",
      "Epoch [17/50], Step [40/42] Train Loss: 0.4358\n",
      "Train loss at epoch 17 is 0.3902\n",
      "Train acc at epoch 17 is 95.2381\n",
      "Val loss at epoch 17 is 0.2388\n",
      "Val acc at epoch 17 is 93.4952\n",
      "Epoch [18/50], Step [10/42] Train Loss: 0.3792\n",
      "Epoch [18/50], Step [20/42] Train Loss: 0.4297\n",
      "Epoch [18/50], Step [30/42] Train Loss: 0.3546\n",
      "Epoch [18/50], Step [40/42] Train Loss: 0.4000\n",
      "Train loss at epoch 18 is 0.3786\n",
      "Train acc at epoch 18 is 95.5729\n",
      "Val loss at epoch 18 is 0.2570\n",
      "Val acc at epoch 18 is 93.6821\n",
      "Epoch [19/50], Step [10/42] Train Loss: 0.3311\n",
      "Epoch [19/50], Step [20/42] Train Loss: 0.3820\n",
      "Epoch [19/50], Step [30/42] Train Loss: 0.3977\n",
      "Epoch [19/50], Step [40/42] Train Loss: 0.3853\n",
      "Train loss at epoch 19 is 0.3653\n",
      "Train acc at epoch 19 is 95.5729\n",
      "Val loss at epoch 19 is 0.2470\n",
      "Val acc at epoch 19 is 93.7670\n",
      "Epoch [20/50], Step [10/42] Train Loss: 0.2842\n",
      "Epoch [20/50], Step [20/42] Train Loss: 0.3903\n",
      "Epoch [20/50], Step [30/42] Train Loss: 0.3544\n",
      "Epoch [20/50], Step [40/42] Train Loss: 0.3247\n",
      "Train loss at epoch 20 is 0.3531\n",
      "Train acc at epoch 20 is 96.0193\n",
      "Val loss at epoch 20 is 0.2585\n",
      "Val acc at epoch 20 is 94.2086\n",
      "Epoch [21/50], Step [10/42] Train Loss: 0.3383\n",
      "Epoch [21/50], Step [20/42] Train Loss: 0.2533\n",
      "Epoch [21/50], Step [30/42] Train Loss: 0.3655\n",
      "Epoch [21/50], Step [40/42] Train Loss: 0.3438\n",
      "Train loss at epoch 21 is 0.3395\n",
      "Train acc at epoch 21 is 96.2054\n",
      "Val loss at epoch 21 is 0.2183\n",
      "Val acc at epoch 21 is 94.3954\n",
      "Epoch [22/50], Step [10/42] Train Loss: 0.2788\n",
      "Epoch [22/50], Step [20/42] Train Loss: 0.2808\n",
      "Epoch [22/50], Step [30/42] Train Loss: 0.2616\n",
      "Epoch [22/50], Step [40/42] Train Loss: 0.3657\n",
      "Train loss at epoch 22 is 0.3359\n",
      "Train acc at epoch 22 is 96.3728\n",
      "Val loss at epoch 22 is 0.2991\n",
      "Val acc at epoch 22 is 94.5143\n",
      "Epoch [23/50], Step [10/42] Train Loss: 0.3902\n",
      "Epoch [23/50], Step [20/42] Train Loss: 0.3011\n",
      "Epoch [23/50], Step [30/42] Train Loss: 0.3420\n",
      "Epoch [23/50], Step [40/42] Train Loss: 0.3450\n",
      "Train loss at epoch 23 is 0.3329\n",
      "Train acc at epoch 23 is 96.3170\n",
      "Val loss at epoch 23 is 0.2712\n",
      "Val acc at epoch 23 is 94.4463\n",
      "Epoch [24/50], Step [10/42] Train Loss: 0.2965\n",
      "Epoch [24/50], Step [20/42] Train Loss: 0.3634\n",
      "Epoch [24/50], Step [30/42] Train Loss: 0.2929\n",
      "Epoch [24/50], Step [40/42] Train Loss: 0.3736\n",
      "Train loss at epoch 24 is 0.3289\n",
      "Train acc at epoch 24 is 96.4844\n",
      "Val loss at epoch 24 is 0.1907\n",
      "Val acc at epoch 24 is 94.6671\n",
      "Epoch [25/50], Step [10/42] Train Loss: 0.2897\n",
      "Epoch [25/50], Step [20/42] Train Loss: 0.3173\n",
      "Epoch [25/50], Step [30/42] Train Loss: 0.3483\n",
      "Epoch [25/50], Step [40/42] Train Loss: 0.3983\n",
      "Train loss at epoch 25 is 0.3253\n",
      "Train acc at epoch 25 is 96.6146\n",
      "Val loss at epoch 25 is 0.2393\n",
      "Val acc at epoch 25 is 94.7181\n",
      "Epoch [26/50], Step [10/42] Train Loss: 0.3350\n",
      "Epoch [26/50], Step [20/42] Train Loss: 0.3238\n",
      "Epoch [26/50], Step [30/42] Train Loss: 0.3181\n",
      "Epoch [26/50], Step [40/42] Train Loss: 0.3526\n",
      "Train loss at epoch 26 is 0.3213\n",
      "Train acc at epoch 26 is 96.6890\n",
      "Val loss at epoch 26 is 0.2464\n",
      "Val acc at epoch 26 is 94.8030\n",
      "Epoch [27/50], Step [10/42] Train Loss: 0.2824\n",
      "Epoch [27/50], Step [20/42] Train Loss: 0.2839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [30/42] Train Loss: 0.3470\n",
      "Epoch [27/50], Step [40/42] Train Loss: 0.3153\n",
      "Train loss at epoch 27 is 0.3175\n",
      "Train acc at epoch 27 is 96.8006\n",
      "Val loss at epoch 27 is 0.2327\n",
      "Val acc at epoch 27 is 94.9898\n",
      "Epoch [28/50], Step [10/42] Train Loss: 0.3664\n",
      "Epoch [28/50], Step [20/42] Train Loss: 0.2951\n",
      "Epoch [28/50], Step [30/42] Train Loss: 0.3298\n",
      "Epoch [28/50], Step [40/42] Train Loss: 0.3384\n",
      "Train loss at epoch 28 is 0.3145\n",
      "Train acc at epoch 28 is 96.8750\n",
      "Val loss at epoch 28 is 0.2171\n",
      "Val acc at epoch 28 is 94.9558\n",
      "Epoch [29/50], Step [10/42] Train Loss: 0.3536\n",
      "Epoch [29/50], Step [20/42] Train Loss: 0.2716\n",
      "Epoch [29/50], Step [30/42] Train Loss: 0.3306\n",
      "Epoch [29/50], Step [40/42] Train Loss: 0.3312\n",
      "Train loss at epoch 29 is 0.3104\n",
      "Train acc at epoch 29 is 96.9494\n",
      "Val loss at epoch 29 is 0.2044\n",
      "Val acc at epoch 29 is 95.0747\n",
      "Epoch [30/50], Step [10/42] Train Loss: 0.2523\n",
      "Epoch [30/50], Step [20/42] Train Loss: 0.3062\n",
      "Epoch [30/50], Step [30/42] Train Loss: 0.2708\n",
      "Epoch [30/50], Step [40/42] Train Loss: 0.3810\n",
      "Train loss at epoch 30 is 0.3071\n",
      "Train acc at epoch 30 is 97.0052\n",
      "Val loss at epoch 30 is 0.2669\n",
      "Val acc at epoch 30 is 95.1257\n",
      "Epoch [31/50], Step [10/42] Train Loss: 0.3073\n",
      "Epoch [31/50], Step [20/42] Train Loss: 0.2918\n",
      "Epoch [31/50], Step [30/42] Train Loss: 0.2844\n",
      "Epoch [31/50], Step [40/42] Train Loss: 0.3581\n",
      "Train loss at epoch 31 is 0.3030\n",
      "Train acc at epoch 31 is 97.1168\n",
      "Val loss at epoch 31 is 0.2389\n",
      "Val acc at epoch 31 is 95.1257\n",
      "Epoch [32/50], Step [10/42] Train Loss: 0.2728\n",
      "Epoch [32/50], Step [20/42] Train Loss: 0.3131\n",
      "Epoch [32/50], Step [30/42] Train Loss: 0.2947\n",
      "Epoch [32/50], Step [40/42] Train Loss: 0.3045\n",
      "Train loss at epoch 32 is 0.3016\n",
      "Train acc at epoch 32 is 97.1354\n",
      "Val loss at epoch 32 is 0.2019\n",
      "Val acc at epoch 32 is 95.1766\n",
      "Epoch [33/50], Step [10/42] Train Loss: 0.2820\n",
      "Epoch [33/50], Step [20/42] Train Loss: 0.3340\n",
      "Epoch [33/50], Step [30/42] Train Loss: 0.2710\n",
      "Epoch [33/50], Step [40/42] Train Loss: 0.3210\n",
      "Train loss at epoch 33 is 0.3000\n",
      "Train acc at epoch 33 is 97.1912\n",
      "Val loss at epoch 33 is 0.1847\n",
      "Val acc at epoch 33 is 95.2106\n",
      "Epoch [34/50], Step [10/42] Train Loss: 0.3168\n",
      "Epoch [34/50], Step [20/42] Train Loss: 0.2642\n",
      "Epoch [34/50], Step [30/42] Train Loss: 0.3002\n",
      "Epoch [34/50], Step [40/42] Train Loss: 0.2393\n",
      "Train loss at epoch 34 is 0.2989\n",
      "Train acc at epoch 34 is 97.1912\n",
      "Val loss at epoch 34 is 0.2343\n",
      "Val acc at epoch 34 is 95.2446\n",
      "Epoch [35/50], Step [10/42] Train Loss: 0.3027\n",
      "Epoch [35/50], Step [20/42] Train Loss: 0.3174\n",
      "Epoch [35/50], Step [30/42] Train Loss: 0.3305\n",
      "Epoch [35/50], Step [40/42] Train Loss: 0.2177\n",
      "Train loss at epoch 35 is 0.2978\n",
      "Train acc at epoch 35 is 97.1912\n",
      "Val loss at epoch 35 is 0.2176\n",
      "Val acc at epoch 35 is 95.3635\n",
      "Epoch [36/50], Step [10/42] Train Loss: 0.2653\n",
      "Epoch [36/50], Step [20/42] Train Loss: 0.3340\n",
      "Epoch [36/50], Step [30/42] Train Loss: 0.2825\n",
      "Epoch [36/50], Step [40/42] Train Loss: 0.3400\n",
      "Train loss at epoch 36 is 0.2970\n",
      "Train acc at epoch 36 is 97.1912\n",
      "Val loss at epoch 36 is 0.2689\n",
      "Val acc at epoch 36 is 95.3125\n",
      "Epoch [37/50], Step [10/42] Train Loss: 0.2365\n",
      "Epoch [37/50], Step [20/42] Train Loss: 0.2695\n",
      "Epoch [37/50], Step [30/42] Train Loss: 0.3202\n",
      "Epoch [37/50], Step [40/42] Train Loss: 0.3757\n",
      "Train loss at epoch 37 is 0.2958\n",
      "Train acc at epoch 37 is 97.1912\n",
      "Val loss at epoch 37 is 0.2155\n",
      "Val acc at epoch 37 is 95.2446\n",
      "Epoch [38/50], Step [10/42] Train Loss: 0.2713\n",
      "Epoch [38/50], Step [20/42] Train Loss: 0.3901\n",
      "Epoch [38/50], Step [30/42] Train Loss: 0.2908\n",
      "Epoch [38/50], Step [40/42] Train Loss: 0.2644\n",
      "Train loss at epoch 38 is 0.2941\n",
      "Train acc at epoch 38 is 97.2284\n",
      "Val loss at epoch 38 is 0.2799\n",
      "Val acc at epoch 38 is 95.3125\n",
      "Epoch [39/50], Step [10/42] Train Loss: 0.3198\n",
      "Epoch [39/50], Step [20/42] Train Loss: 0.2930\n",
      "Epoch [39/50], Step [30/42] Train Loss: 0.2520\n",
      "Epoch [39/50], Step [40/42] Train Loss: 0.2736\n",
      "Train loss at epoch 39 is 0.2932\n",
      "Train acc at epoch 39 is 97.2470\n",
      "Val loss at epoch 39 is 0.2495\n",
      "Val acc at epoch 39 is 95.2785\n",
      "Epoch [40/50], Step [10/42] Train Loss: 0.2788\n",
      "Epoch [40/50], Step [20/42] Train Loss: 0.3155\n",
      "Epoch [40/50], Step [30/42] Train Loss: 0.2834\n",
      "Epoch [40/50], Step [40/42] Train Loss: 0.2689\n",
      "Train loss at epoch 40 is 0.2914\n",
      "Train acc at epoch 40 is 97.2284\n",
      "Val loss at epoch 40 is 0.2398\n",
      "Val acc at epoch 40 is 95.4314\n",
      "Epoch [41/50], Step [10/42] Train Loss: 0.3433\n",
      "Epoch [41/50], Step [20/42] Train Loss: 0.3006\n",
      "Epoch [41/50], Step [30/42] Train Loss: 0.2416\n",
      "Epoch [41/50], Step [40/42] Train Loss: 0.2958\n",
      "Train loss at epoch 41 is 0.2907\n",
      "Train acc at epoch 41 is 97.2470\n",
      "Val loss at epoch 41 is 0.2665\n",
      "Val acc at epoch 41 is 95.3635\n",
      "Epoch [42/50], Step [10/42] Train Loss: 0.2736\n",
      "Epoch [42/50], Step [20/42] Train Loss: 0.2700\n",
      "Epoch [42/50], Step [30/42] Train Loss: 0.3246\n",
      "Epoch [42/50], Step [40/42] Train Loss: 0.2489\n",
      "Train loss at epoch 42 is 0.2900\n",
      "Train acc at epoch 42 is 97.2284\n",
      "Val loss at epoch 42 is 0.2571\n",
      "Val acc at epoch 42 is 95.2106\n",
      "Epoch [43/50], Step [10/42] Train Loss: 0.2488\n",
      "Epoch [43/50], Step [20/42] Train Loss: 0.2651\n",
      "Epoch [43/50], Step [30/42] Train Loss: 0.2776\n",
      "Epoch [43/50], Step [40/42] Train Loss: 0.2807\n",
      "Train loss at epoch 43 is 0.2896\n",
      "Train acc at epoch 43 is 97.2842\n",
      "Val loss at epoch 43 is 0.2155\n",
      "Val acc at epoch 43 is 95.4144\n",
      "Epoch [44/50], Step [10/42] Train Loss: 0.2835\n",
      "Epoch [44/50], Step [20/42] Train Loss: 0.3682\n",
      "Epoch [44/50], Step [30/42] Train Loss: 0.2700\n",
      "Epoch [44/50], Step [40/42] Train Loss: 0.2409\n",
      "Train loss at epoch 44 is 0.2893\n",
      "Train acc at epoch 44 is 97.2470\n",
      "Val loss at epoch 44 is 0.1866\n",
      "Val acc at epoch 44 is 95.2785\n",
      "Epoch [45/50], Step [10/42] Train Loss: 0.2401\n",
      "Epoch [45/50], Step [20/42] Train Loss: 0.2962\n",
      "Epoch [45/50], Step [30/42] Train Loss: 0.2739\n",
      "Epoch [45/50], Step [40/42] Train Loss: 0.3061\n",
      "Train loss at epoch 45 is 0.2886\n",
      "Train acc at epoch 45 is 97.2470\n",
      "Val loss at epoch 45 is 0.2059\n",
      "Val acc at epoch 45 is 95.2955\n",
      "Epoch [46/50], Step [10/42] Train Loss: 0.2953\n",
      "Epoch [46/50], Step [20/42] Train Loss: 0.2291\n",
      "Epoch [46/50], Step [30/42] Train Loss: 0.2772\n",
      "Epoch [46/50], Step [40/42] Train Loss: 0.2541\n",
      "Train loss at epoch 46 is 0.2882\n",
      "Train acc at epoch 46 is 97.3214\n",
      "Val loss at epoch 46 is 0.2390\n",
      "Val acc at epoch 46 is 95.3125\n",
      "Epoch [47/50], Step [10/42] Train Loss: 0.2867\n",
      "Epoch [47/50], Step [20/42] Train Loss: 0.3398\n",
      "Epoch [47/50], Step [30/42] Train Loss: 0.2983\n",
      "Epoch [47/50], Step [40/42] Train Loss: 0.2674\n",
      "Train loss at epoch 47 is 0.2881\n",
      "Train acc at epoch 47 is 97.2842\n",
      "Val loss at epoch 47 is 0.2071\n",
      "Val acc at epoch 47 is 95.3295\n",
      "Epoch [48/50], Step [10/42] Train Loss: 0.2860\n",
      "Epoch [48/50], Step [20/42] Train Loss: 0.2837\n",
      "Epoch [48/50], Step [30/42] Train Loss: 0.2971\n",
      "Epoch [48/50], Step [40/42] Train Loss: 0.3315\n",
      "Train loss at epoch 48 is 0.2870\n",
      "Train acc at epoch 48 is 97.3400\n",
      "Val loss at epoch 48 is 0.2851\n",
      "Val acc at epoch 48 is 95.3804\n",
      "Epoch [49/50], Step [10/42] Train Loss: 0.3430\n",
      "Epoch [49/50], Step [20/42] Train Loss: 0.3206\n",
      "Epoch [49/50], Step [30/42] Train Loss: 0.3279\n",
      "Epoch [49/50], Step [40/42] Train Loss: 0.2704\n",
      "Train loss at epoch 49 is 0.2869\n",
      "Train acc at epoch 49 is 97.3214\n",
      "Val loss at epoch 49 is 0.2485\n",
      "Val acc at epoch 49 is 95.3804\n",
      "Epoch [50/50], Step [10/42] Train Loss: 0.3297\n",
      "Epoch [50/50], Step [20/42] Train Loss: 0.2791\n",
      "Epoch [50/50], Step [30/42] Train Loss: 0.3058\n",
      "Epoch [50/50], Step [40/42] Train Loss: 0.2824\n",
      "Train loss at epoch 50 is 0.2865\n",
      "Train acc at epoch 50 is 97.3400\n",
      "Val loss at epoch 50 is 0.2510\n",
      "Val acc at epoch 50 is 95.3635\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "curr_lr = learning_rate\n",
    "# val_losses = np.array([])\n",
    "# train_losses = np.array([])\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "\n",
    "myfile = open('myfile_cubx_txt', 'w')\n",
    "myfile.write('Training results: \\n')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    correct=0\n",
    "    total=0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        # print(images.shape)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimizes\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Train Loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    acc = 100.*correct/total\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(acc)\n",
    "    print('Train loss at epoch {} is {:.4f}'.format(epoch+1, train_loss))\n",
    "    print('Train acc at epoch {} is {:.4f}'.format(epoch+1, acc))\n",
    "    myfile.write('Train loss at epoch {} is {:.4f}\\n'.format(epoch+1, train_loss))\n",
    "    myfile.write('Train acc at epoch {} is {:.4f}\\n'.format(epoch+1, acc))\n",
    "    myfile.write('---------------------------')\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    val_loss = loss / len(val_loader) \n",
    "    acc = 100.*correct/total\n",
    "    val_losses.append(val_loss)\n",
    "    val_acc.append(acc)\n",
    "    print('Val loss at epoch {} is {:.4f}'.format(epoch+1, val_loss))\n",
    "    print('Val acc at epoch {} is {:.4f}'.format(epoch+1, acc))\n",
    "    myfile.write('Val loss at epoch {} is {:.4f}\\n'.format(epoch+1, val_loss))\n",
    "    myfile.write('Val acc at epoch {} is {:.4f}\\n'.format(epoch+1, acc))    \n",
    "    myfile.write('---------------------------\\n')\n",
    "    myfile.write('---------------------------\\n')\n",
    "    # Decay learning rate\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "\n",
    "myfile.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'model_checkpoints/model_resnetv2_cub_epoch50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train','Valid'])\n",
    "plt.title('Train vs Valid Accuracy')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (stem): Sequential(\n",
       "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ResNetStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): PreActBottleneck(\n",
       "          (downsample): DownsampleConv(\n",
       "            (conv): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 64, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResNetStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): PreActBottleneck(\n",
       "          (downsample): DownsampleConv(\n",
       "            (conv): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 128, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResNetStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): PreActBottleneck(\n",
       "          (downsample): DownsampleConv(\n",
       "            (conv): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 256, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResNetStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): PreActBottleneck(\n",
       "          (downsample): DownsampleConv(\n",
       "            (conv): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (norm): Identity()\n",
       "          )\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 1024, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 2048, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): PreActBottleneck(\n",
       "          (norm1): GroupNormAct(\n",
       "            32, 2048, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm3): GroupNormAct(\n",
       "            32, 512, eps=1e-05, affine=True\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): GroupNormAct(\n",
       "    32, 2048, eps=1e-05, affine=True\n",
       "    (act): ReLU(inplace=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Conv2d(2048, 200, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load('model_checkpoints/model_resnetv2_cub_epoch50.pth'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 77.37314463237833 %\n"
     ]
    }
   ],
   "source": [
    " # Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cc289c304aa67a903225ac755337f14ca9e86f378cf8d96233e0cc690cb604b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
